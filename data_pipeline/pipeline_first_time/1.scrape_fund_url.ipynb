{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium_stealth import stealth\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil import tz\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "\n",
    "import undetected_chromedriver as uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_date = (datetime.datetime.now(tz=tz.gettz('Asia/Singapore'))).strftime('%Y%m%d')\n",
    "urls_output_dir = f'../../data/raw/{today_date}/urls'\n",
    "funds_output_dir = f'../../data/raw/{today_date}/funds'\n",
    "\n",
    "os.makedirs(urls_output_dir, exist_ok=True)\n",
    "os.makedirs(funds_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium stealth driver used for scraping \n",
    "def create_driver(debug=False):\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    if debug==False:\n",
    "        options.add_argument(\"--headless\")\n",
    "    # options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    # options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver = uc.Chrome(\n",
    "        options=options\n",
    "    )\n",
    "    stealth(driver,\n",
    "            # user_agent=agent,\n",
    "            languages=[\"en-US\", \"en\"],\n",
    "            vendor=\"Google Inc.\",\n",
    "            platform=\"Win32\",\n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "            renderer=\"Intel Iris OpenGL Engine\",\n",
    "            fix_hairline=True,\n",
    "            )\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Fund URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_fund_url(output_dir):\n",
    "    url = 'https://investor.vanguard.com/investment-products/list/all'\n",
    "    driver = create_driver()\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(random.uniform(3,5))\n",
    "    nxt_button = True\n",
    "    page_count = 0\n",
    "\n",
    "    try:\n",
    "        fund_urls = {}\n",
    "        while nxt_button:\n",
    "            page_count+=1\n",
    "            table = driver.find_element(By.XPATH,\"//div[@class='col-md-9 col-sm-12']\")\n",
    "            table_body = table.find_element(By.TAG_NAME,'tbody')\n",
    "            table_rows = table_body.find_elements(By.TAG_NAME,'tr')\n",
    "            for row in table_rows:\n",
    "\n",
    "                symbol = row.find_element(By.TAG_NAME,'span').text\n",
    "                fund_url = row.find_element(By.TAG_NAME,'a').get_attribute('href')\n",
    "                fund_urls[symbol] = fund_url\n",
    "            button = driver.find_element(By.ID,'next-page-btn')\n",
    "            button.location_once_scrolled_into_view\n",
    "            time.sleep(random.uniform(1,2))\n",
    "            if button.find_element(By.TAG_NAME,'vui-icon').get_attribute('class') == 'disabled':\n",
    "                nxt_button=False\n",
    "            else:\n",
    "                button.click()\n",
    "                time.sleep(random.uniform(1,2))\n",
    "        driver.quit()\n",
    "        output_file = output_dir+'/funds_url.json'\n",
    "        with open(output_file,'w') as f:\n",
    "            json.dump(fund_urls,f)\n",
    "    except:\n",
    "        print(symbol,page_count)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_fund_url(output_dir=urls_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Fund Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fund_details(html_page_source,fund_detail,symbol,driver):\n",
    "    dashboard = html_page_source.find(name='section',attrs={'id':'Dashboard'})\n",
    "    if dashboard:\n",
    "        fund_name = dashboard.find(name='h1',attrs={'class':'fund-name rps-display-two'}).text\n",
    "        fund_detail['name'] = fund_name\n",
    "    \n",
    "    overview = html_page_source.find(name='div',attrs={'id':'overview_section'})\n",
    "    if overview:\n",
    "        key_fact_table = overview.find(name='table',attrs={'class':'table key-fact-table'})\n",
    "        if key_fact_table:\n",
    "            fund_detail['key_fact_table'] = {}\n",
    "            for row in key_fact_table.find('tbody').find_all('tr'):\n",
    "                key = row.find('th').text\n",
    "                value = row.find('td').text\n",
    "                fund_detail['key_fact_table'][key] = value\n",
    "\n",
    "        risk_tag = overview.find(name='div',attrs={'data-rpa-tag-id':\"risk\"})\n",
    "        if risk_tag:\n",
    "            fund_detail['risk_level'] = risk_tag.text\n",
    "        \n",
    "        ppf_container = overview.find(name='div',attrs={'class':'col-lg-4 col-sm-12 ppf-container'})\n",
    "        if ppf_container:\n",
    "            ytd_percent = ppf_container.find(name='h4',attrs={'data-rpa-tag-id':'ytdPercent'})\n",
    "            ytd_percent_market = ppf_container.find(name='h4',attrs={'data-rpa-tag-id':'ytdPercentMarket'})\n",
    "            ytd_percent_nav = ppf_container.find(name='h4',attrs={'data-rpa-tag-id':'ytdPercentNAV'})\n",
    "            if ytd_percent:\n",
    "                fund_detail['ytd_returns'] = ytd_percent.text\n",
    "            if ytd_percent_market:\n",
    "                fund_detail['ytd_market_returns'] = ytd_percent_market.text\n",
    "            if ytd_percent_nav:\n",
    "                fund_detail['ytd_nav_returns'] = ytd_percent_nav.text\n",
    "        \n",
    "        product_summary = overview.find(name='div',attrs={'data-rpa-tag-id':'productSummary'})\n",
    "        if product_summary:\n",
    "            if product_summary.find('p'):\n",
    "                fund_detail['product_summary'] = product_summary.find('p').text\n",
    "            elif product_summary.find_all('li'):\n",
    "                summary_text = \"\"\n",
    "                for li in product_summary.find_all('li'):\n",
    "                    summary_text = summary_text+li.text\n",
    "                fund_detail['product_summary'] = summary_text\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        min_inv = overview.find(name='h4',attrs={'data-rpa-tag-id':'minInvestment'})\n",
    "        if min_inv:\n",
    "            fund_detail['min_investment'] = min_inv.text\n",
    "        \n",
    "        exp_ratio = overview.find(name='h4',attrs={'data-rpa-tag-id':'expenseRatio'})\n",
    "        if exp_ratio:\n",
    "            fund_detail['exp_ratio'] = exp_ratio.text\n",
    "        \n",
    "    perf = html_page_source.find(name='div',attrs={'id':'performance-fees_section'})\n",
    "    if perf:\n",
    "        perf_table = perf.find(name='table',attrs={'aria-label':'Performance summary'})\n",
    "        if perf_table:\n",
    "            fund_detail['perf_table'] = {'index':['Month-end','3-Month total','YTD','1-yr','3-yr','5-yr','10-yr','Since inception']}\n",
    "            for row in perf_table.find('tbody').find_all('tr'):\n",
    "                values = []\n",
    "                for td in row.find_all('td'):\n",
    "                    values.append(td.text)\n",
    "                fund_detail['perf_table'][row.find('th').text] = values\n",
    "    \n",
    "    fund_detail['historical_price_table'] = {}\n",
    "    if html_page_source.find(name='div',attrs={'id':'mat-tab-label-0-3'}):\n",
    "        tab_1_year = driver.find_element(By.ID,'mat-tab-label-0-3')    \n",
    "        tab_1_year.location_once_scrolled_into_view\n",
    "        time.sleep(random.uniform(1,2))\n",
    "        tab_1_year.click()\n",
    "        \n",
    "        time.sleep(random.uniform(2,4))\n",
    "        radio_button = driver.find_element(By.XPATH,\"//input[@type='radio' and @aria-label='table']\")\n",
    "        radio_button.click()\n",
    "        time.sleep(random.uniform(2,4))\n",
    "\n",
    "        listbox_location = driver.find_element(By.XPATH,\"//button[@tabindex='0' and @aria-haspopup='listbox']\")\n",
    "        dates = []\n",
    "        daily_prices = []\n",
    "        listbox_location.click()\n",
    "        time.sleep(random.uniform(0,0.5))\n",
    "\n",
    "        overlay_container = driver.find_element(By.XPATH,\"//div[@class='cdk-overlay-container']\")\n",
    "        driver.find_element(By.XPATH,\"//table[@aria-label='Historical prices table']\").location_once_scrolled_into_view\n",
    "        time.sleep(random.uniform(1,2))\n",
    "        listbox = overlay_container.find_element(By.XPATH,\"//div[@role='listbox' and @tabindex='0']\")\n",
    "        num_options = len(listbox.find_elements(By.TAG_NAME,'vui-option'))\n",
    "        for index,option in enumerate(listbox.find_elements(By.TAG_NAME,'vui-option')):\n",
    "            option.location_once_scrolled_into_view\n",
    "            time.sleep(random.uniform(0.5,1))\n",
    "            option.click()\n",
    "            time.sleep(random.uniform(0.5,1))\n",
    "            updated_page_source = BeautifulSoup(driver.page_source)\n",
    "            price = updated_page_source.find(name='div',attrs={'id':'price_section'})\n",
    "            for tr in price.find(name='table',attrs={'aria-label':'Historical prices table'}).find('tbody').find_all('tr'):\n",
    "                dates.append(tr.find(name='td',attrs={'data-rpa-tag-id':'historicalDate'}).text)\n",
    "                daily_prices.append(tr.find(name='td',attrs={'data-rpa-tag-id':'historicalPrice'}).text)\n",
    "\n",
    "            if index == num_options-1:\n",
    "                break\n",
    "            listbox_location.click()\n",
    "            time.sleep(random.uniform(0.5,1))\n",
    "\n",
    "        fund_detail['historical_price_table']['date'] = dates\n",
    "        fund_detail['historical_price_table']['price'] = daily_prices\n",
    "\n",
    "    fundamental_table = html_page_source.find(name='div',attrs={'id':'characteristics-tabset'})\n",
    "    fund_detail['portfolio_fundamental_table'] = {}\n",
    "    if fundamental_table:\n",
    "        trs = fundamental_table.find_all('tr')\n",
    "        fundamental_list = []\n",
    "        fund_list = []\n",
    "        benchmark_list = []\n",
    "        for tr in trs[1:]:\n",
    "            tds = tr.find_all('td')\n",
    "            for index,td in enumerate(tds):\n",
    "                if index==0:\n",
    "                    fundamental_list.append(td.text)\n",
    "                elif index==1:\n",
    "                    fund_list.append(td.text)\n",
    "                else:\n",
    "                    benchmark_list.append(td.text)\n",
    "        fund_detail['portfolio_fundamental_table']['fundamentals'] = fundamental_list\n",
    "        fund_detail['portfolio_fundamental_table'][symbol] = fund_list\n",
    "        fund_detail['portfolio_fundamental_table']['benchmark'] = benchmark_list\n",
    "    \n",
    "\n",
    "    fund_detail['weighted_exposure_table'] = {}\n",
    "    if html_page_source.find(name='vui-tab-group',attrs={'id':'weighting-prices-tabset'}):\n",
    "        tab_list = driver.find_element(By.ID,'weighting-prices-tabset').find_element(By.CSS_SELECTOR,'.vui-tabs-container.vui-tab-not-contained-style').find_elements(By.TAG_NAME,'button')\n",
    "        driver.find_element(By.XPATH,\"//exemplar-weighting-exposure\").location_once_scrolled_into_view\n",
    "        time.sleep(random.uniform(1,2))\n",
    "        for button in tab_list:\n",
    "            exposure_type = BeautifulSoup(button.get_attribute('outerHTML'),'html.parser').find('div').text\n",
    "            button.click()\n",
    "            time.sleep(random.uniform(1,2))\n",
    "            updated_page_source = BeautifulSoup(driver.page_source)\n",
    "            asset_allocation_table = updated_page_source.find(name='mat-table',attrs={'id':'assetAllocationTable'})\n",
    "            rows = asset_allocation_table.find_all(name='mat-row',attrs={'role':'row'})\n",
    "            exposure_type_list = []\n",
    "            symbol_list = []\n",
    "            benchmark_list = []\n",
    "            weight_difference_list = []\n",
    "            for row in rows:\n",
    "                for cell in row.find_all(name='mat-cell'):\n",
    "                    span = cell.find('span')\n",
    "                    if span:\n",
    "                        data_rpa_tag_id = span.get('data-rpa-tag-id')\n",
    "                        if data_rpa_tag_id==\"weightedExposuresTab\":\n",
    "                            exposure_type_list.append(span.text)\n",
    "                        \n",
    "                        if data_rpa_tag_id=='symbol_LongPct':\n",
    "                            symbol_list.append(span.text)\n",
    "                        \n",
    "                        if data_rpa_tag_id=='benchmark_ShortPct':\n",
    "                            benchmark_list.append(span.text)\n",
    "                        \n",
    "                        if data_rpa_tag_id=='weightPct':\n",
    "                            weight_difference_list.append(span.text)\n",
    "\n",
    "            fund_detail['weighted_exposure_table'][exposure_type] = {}\n",
    "            fund_detail['weighted_exposure_table'][exposure_type][exposure_type] = exposure_type_list\n",
    "            fund_detail['weighted_exposure_table'][exposure_type][symbol] = symbol_list\n",
    "            fund_detail['weighted_exposure_table'][exposure_type][\"Benchmark\"] = benchmark_list\n",
    "            fund_detail['weighted_exposure_table'][exposure_type]['+/-Weight'] = weight_difference_list\n",
    "    \n",
    "    return fund_detail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/raw/20231212/urls/funds_url.json','r')as f:\n",
    "    funds_url = json.load(f)\n",
    "\n",
    "try:\n",
    "    for index,(symbol,url) in enumerate(funds_url.items()):            \n",
    "        driver = create_driver()\n",
    "        fund_detail = {}\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(1,1.5))\n",
    "        soup = BeautifulSoup(driver.page_source)\n",
    "        fund_detail = extract_fund_details(soup,fund_detail,symbol,driver)\n",
    "        with open(f\"{funds_output_dir}/{symbol}.json\",'w') as f:\n",
    "            json.dump(fund_detail,f)\n",
    "        driver.quit()\n",
    "except Exception as e:\n",
    "    print(f\"ERROR --> {symbol}, Index --> {index}\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix Fund Name & Risk Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name_and_risk(html_page_source,fund_detail):\n",
    "    \n",
    "    dashboard = html_page_source.find(name='section',attrs={'id':'Dashboard'})\n",
    "    if dashboard:\n",
    "        fund_name = dashboard.find(name='h1',attrs={'class':'fund-name rps-display-two'}).text\n",
    "        fund_detail['name'] = fund_name\n",
    "    \n",
    "    overview = html_page_source.find(name='div',attrs={'id':'overview_section'})\n",
    "    if overview:\n",
    "        risk_tag = overview.find(name='div',attrs={'data-rpa-tag-id':\"risk\"})\n",
    "        if risk_tag:\n",
    "            fund_detail['risk_level'] = risk_tag.text\n",
    "    return fund_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('../../data/raw/20231212/urls/funds_url.json','r')as f:\n",
    "    funds_url = json.load(f)\n",
    "\n",
    "try:\n",
    "    for index,(symbol,url) in enumerate(funds_url.items()):\n",
    "        if index==83:\n",
    "            driver = create_driver()\n",
    "            with open(f\"{funds_output_dir}/{symbol}.json\",'r') as f:\n",
    "                fund_detail = json.load(f)\n",
    "            driver.get(url)\n",
    "            time.sleep(random.uniform(0.5,1))\n",
    "            soup = BeautifulSoup(driver.page_source)\n",
    "            fund_detail = extract_name_and_risk(soup,fund_detail)\n",
    "            with open(f\"{funds_output_dir}/{symbol}.json\",'w') as f:\n",
    "                json.dump(fund_detail,f)\n",
    "            driver.quit()\n",
    "except Exception as e:\n",
    "    print(f\"ERROR --> {symbol}, Index --> {index}\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 VFIAX\n",
      "1 VADGX\n",
      "2 VAGVX\n",
      "3 VAIGX\n",
      "4 VBPIX\n",
      "5 VBIAX\n",
      "6 VBAIX\n",
      "7 VCADX\n",
      "8 VCAIX\n",
      "9 VCLAX\n",
      "10 VCITX\n",
      "11 VCTXX\n",
      "12 VHCAX\n",
      "13 VHCOX\n",
      "14 VMRXX\n",
      "15 VCMDX\n",
      "16 VOX\n",
      "17 VTCAX\n",
      "18 VCR\n",
      "19 VCDAX\n",
      "20 VDC\n",
      "21 VCSAX\n",
      "22 VCOBX\n",
      "23 VCORX\n",
      "24 VPLS\n",
      "25 VCPAX\n",
      "26 VCPIX\n",
      "27 VTMGX\n",
      "28 VDIPX\n",
      "29 VTMNX\n",
      "30 VDEQX\n",
      "31 VIG\n",
      "32 VDADX\n",
      "33 VDIGX\n",
      "34 VEGBX\n",
      "35 VEMBX\n",
      "36 VWOB\n",
      "37 VGAVX\n",
      "38 VGIVX\n",
      "39 VEMRX\n",
      "40 VMMSX\n",
      "41 VEMAX\n",
      "42 VEMIX\n",
      "43 VDE\n",
      "44 VGELX\n",
      "45 VGENX\n",
      "46 VENAX\n",
      "47 VEIRX\n",
      "48 VEIPX\n",
      "49 VSGX\n",
      "50 VCEB\n",
      "51 ESGV\n",
      "52 VEUSX\n",
      "53 VEUPX\n",
      "54 VESIX\n",
      "55 VEXRX\n",
      "56 VEXPX\n",
      "57 VEVFX\n",
      "58 EDV\n",
      "59 VXF\n",
      "60 VEXAX\n",
      "61 VEMPX\n",
      "62 VIEIX\n",
      "63 VMFXX\n",
      "64 VFH\n",
      "65 VFAIX\n",
      "66 VEU\n",
      "67 VFWAX\n",
      "68 VFWPX\n",
      "69 VFWSX\n",
      "70 VSS\n",
      "71 VFSAX\n",
      "72 VFSNX\n",
      "73 VEA\n",
      "74 VWO\n",
      "75 VGK\n",
      "76 VPL\n",
      "77 VFTAX\n",
      "78 VFTNX\n",
      "79 VGPMX\n",
      "80 VGCAX\n",
      "81 VGCIX\n",
      "82 VEOAX\n",
      "83 VEOIX\n",
      "84 VHGEX\n",
      "85 VESGX\n",
      "86 VEIGX\n",
      "87 VNQI\n",
      "88 VGRLX\n",
      "89 VGRNX\n",
      "90 VMNVX\n",
      "91 VMVFX\n",
      "92 VGYAX\n",
      "93 VGWIX\n",
      "94 VGWAX\n",
      "95 VGWLX\n",
      "96 VFIJX\n",
      "97 VFIIX\n",
      "98 VGIAX\n",
      "99 VQNPX\n",
      "100 VUG\n",
      "101 VIGAX\n",
      "102 VIGIX\n",
      "103 VHT\n",
      "104 VGHAX\n",
      "105 VGHCX\n",
      "106 VHCIX\n",
      "107 VYM\n",
      "108 VHYAX\n",
      "109 VWEAX\n",
      "110 VWEHX\n",
      "111 VWALX\n",
      "112 VWAHX\n",
      "113 VIS\n",
      "114 VINAX\n",
      "115 VAIPX\n",
      "116 VIPIX\n",
      "117 VIPSX\n",
      "118 VGT\n",
      "119 VITAX\n",
      "120 VIIIX\n",
      "121 VINIX\n",
      "122 VITPX\n",
      "123 VITNX\n",
      "124 BIV\n",
      "125 VBILX\n",
      "126 VBIUX\n",
      "127 VBIMX\n",
      "128 VCIT\n",
      "129 VICSX\n",
      "130 VICBX\n",
      "131 VFIDX\n",
      "132 VFICX\n",
      "133 VWIUX\n",
      "134 VWITX\n",
      "135 VGIT\n",
      "136 VFIUX\n",
      "137 VFITX\n",
      "138 VSIGX\n",
      "139 VIIGX\n",
      "140 VZICX\n",
      "141 VWICX\n",
      "142 VIGI\n",
      "143 VIAAX\n",
      "144 VIDGX\n",
      "145 VINEX\n",
      "146 VWILX\n",
      "147 VWIGX\n",
      "148 VYMI\n",
      "149 VIHAX\n",
      "150 VTRIX\n",
      "151 VV\n",
      "152 VLCAX\n",
      "153 VLISX\n",
      "154 VSCGX\n",
      "155 VASGX\n",
      "156 VASIX\n",
      "157 VSMGX\n",
      "158 VMLUX\n",
      "159 VMLTX\n",
      "160 BLV\n",
      "161 VBLAX\n",
      "162 VBLIX\n",
      "163 VBLLX\n",
      "164 VCLT\n",
      "165 VLTCX\n",
      "166 VLCIX\n",
      "167 VWETX\n",
      "168 VWESX\n",
      "169 VWLUX\n",
      "170 VWLTX\n",
      "171 VGLT\n",
      "172 VUSUX\n",
      "173 VUSTX\n",
      "174 VLGSX\n",
      "175 VLGIX\n",
      "176 VMNIX\n",
      "177 VMNFX\n",
      "178 VMATX\n",
      "179 VAW\n",
      "180 VMIAX\n",
      "181 MGC\n",
      "182 MGK\n",
      "183 VMGAX\n",
      "184 VMCTX\n",
      "185 MGV\n",
      "186 VMVLX\n",
      "187 VO\n",
      "188 VOT\n",
      "189 VMGRX\n",
      "190 VMGMX\n",
      "191 VIMAX\n",
      "192 VMCPX\n",
      "193 VMCIX\n",
      "194 VOE\n",
      "195 VMVAX\n",
      "196 VMBS\n",
      "197 VMBSX\n",
      "198 VMBIX\n",
      "199 VMSAX\n",
      "200 VMSIX\n",
      "201 VMSXX\n",
      "202 VNJUX\n",
      "203 VNJTX\n",
      "204 VNYUX\n",
      "205 VNYTX\n",
      "206 VYFXX\n",
      "207 VOHIX\n",
      "208 VPADX\n",
      "209 VPKIX\n",
      "210 VPALX\n",
      "211 VPAIX\n",
      "212 VPCCX\n",
      "213 VPMAX\n",
      "214 VPMCX\n",
      "215 VNQ\n",
      "216 VGSLX\n",
      "217 VGSNX\n",
      "218 VONE\n",
      "219 VONG\n",
      "220 VRGWX\n",
      "221 VRNIX\n",
      "222 VONV\n",
      "223 VRVIX\n",
      "224 VTWO\n",
      "225 VTWG\n",
      "226 VRTGX\n",
      "227 VRTIX\n",
      "228 VTWV\n",
      "229 VRTVX\n",
      "230 VTHR\n",
      "231 VRTTX\n",
      "232 VOO\n",
      "233 VOOG\n",
      "234 VSPGX\n",
      "235 VOOV\n",
      "236 VSPVX\n",
      "237 IVOO\n",
      "238 IVOG\n",
      "239 VMFGX\n",
      "240 VSPMX\n",
      "241 IVOV\n",
      "242 VMFVX\n",
      "243 VIOO\n",
      "244 VIOG\n",
      "245 VSGNX\n",
      "246 VSMSX\n",
      "247 VIOV\n",
      "248 VSMVX\n",
      "249 VASVX\n",
      "250 BSV\n",
      "251 VBIRX\n",
      "252 VBIPX\n",
      "253 VBITX\n",
      "254 VCSH\n",
      "255 VSCSX\n",
      "256 VSTBX\n",
      "257 VSGDX\n",
      "258 VSGBX\n",
      "259 VTIP\n",
      "260 VTAPX\n",
      "261 VTSPX\n",
      "262 VFSUX\n",
      "263 VFSIX\n",
      "264 VFSTX\n",
      "265 VTES\n",
      "266 VGSH\n",
      "267 VFIRX\n",
      "268 VFISX\n",
      "269 VSBSX\n",
      "270 VSBIX\n",
      "271 VB\n",
      "272 VBK\n",
      "273 VSGAX\n",
      "274 VSGIX\n",
      "275 VSMAX\n",
      "276 VSCPX\n",
      "277 VSCIX\n",
      "278 VBR\n",
      "279 VSIAX\n",
      "280 VSIIX\n",
      "281 VGSTX\n",
      "282 VSEQX\n",
      "283 VSTCX\n",
      "284 VTWNX\n",
      "285 VTTVX\n",
      "286 VTHRX\n",
      "287 VTTHX\n",
      "288 VFORX\n",
      "289 VTIVX\n",
      "290 VFIFX\n",
      "291 VFFVX\n",
      "292 VTTSX\n",
      "293 VLXVX\n",
      "294 VSVNX\n",
      "295 VTINX\n",
      "296 VTEB\n",
      "297 VTEAX\n",
      "298 VTMFX\n",
      "299 VTCLX\n",
      "300 VTCIX\n",
      "301 VTMSX\n",
      "302 VTSIX\n",
      "303 BND\n",
      "304 VBTLX\n",
      "305 VBMPX\n",
      "306 VBTIX\n",
      "307 VTC\n",
      "308 BNDX\n",
      "309 VTABX\n",
      "310 VTIFX\n",
      "311 VXUS\n",
      "312 VTIAX\n",
      "313 VTPSX\n",
      "314 VTSNX\n",
      "315 VTI\n",
      "316 VTSAX\n",
      "317 VSMPX\n",
      "318 VITSX\n",
      "319 BNDW\n",
      "320 VT\n",
      "321 VTWAX\n",
      "322 VTWIX\n",
      "323 VUSXX\n",
      "324 VWUAX\n",
      "325 VWUSX\n",
      "326 VFMV\n",
      "327 VFMO\n",
      "328 VFMF\n",
      "329 VFMFX\n",
      "330 VFQY\n",
      "331 VFVA\n",
      "332 VUSB\n",
      "333 VUSFX\n",
      "334 VUBFX\n",
      "335 VWSUX\n",
      "336 VWSTX\n",
      "337 VPU\n",
      "338 VUIAX\n",
      "339 VTV\n",
      "340 VVIAX\n",
      "341 VIVIX\n",
      "342 VWIAX\n",
      "343 VWINX\n",
      "344 VWENX\n",
      "345 VWELX\n",
      "346 VWNEX\n",
      "347 VWNDX\n",
      "348 VWNAX\n",
      "349 VWNFX\n"
     ]
    }
   ],
   "source": [
    "for index,(symbol,url) in enumerate(funds_url.items()):\n",
    "    print(index,symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Missing Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_missing_price(html_page_source,fund_detail,driver):\n",
    "\n",
    "    # Only fill in missing price for symbols that have price table\n",
    "    if 'date' in fund_detail['historical_price_table'] and 'price' in fund_detail['historical_price_table']:\n",
    "\n",
    "        if html_page_source.find(name='div',attrs={'id':'mat-tab-label-0-1'}):\n",
    "            tab_3_months = driver.find_element(By.ID,'mat-tab-label-0-1')    \n",
    "            tab_3_months.location_once_scrolled_into_view\n",
    "            time.sleep(random.uniform(1,2))\n",
    "            tab_3_months.click()\n",
    "            \n",
    "            time.sleep(random.uniform(2,4))\n",
    "            radio_button = driver.find_element(By.XPATH,\"//input[@type='radio' and @aria-label='table']\")\n",
    "            radio_button.click()\n",
    "            time.sleep(random.uniform(2,4))\n",
    "\n",
    "            listbox_location = driver.find_element(By.XPATH,\"//button[@tabindex='0' and @aria-haspopup='listbox']\")\n",
    "            listbox_location.click()\n",
    "            time.sleep(random.uniform(0,0.5))\n",
    "\n",
    "            overlay_container = driver.find_element(By.XPATH,\"//div[@class='cdk-overlay-container']\")\n",
    "            driver.find_element(By.XPATH,\"//table[@aria-label='Historical prices table']\").location_once_scrolled_into_view\n",
    "            time.sleep(random.uniform(1,2))\n",
    "            listbox = overlay_container.find_element(By.XPATH,\"//div[@role='listbox' and @tabindex='0']\")\n",
    "            num_options = len(listbox.find_elements(By.TAG_NAME,'vui-option'))\n",
    "            for index,option in enumerate(listbox.find_elements(By.TAG_NAME,'vui-option')):\n",
    "                option.location_once_scrolled_into_view\n",
    "                time.sleep(random.uniform(0.5,1))\n",
    "                option.click()\n",
    "                time.sleep(random.uniform(0.5,1))\n",
    "                updated_page_source = BeautifulSoup(driver.page_source)\n",
    "                price = updated_page_source.find(name='div',attrs={'id':'price_section'})\n",
    "                for tr in price.find(name='table',attrs={'aria-label':'Historical prices table'}).find('tbody').find_all('tr'):\n",
    "                    cur_date = tr.find(name='td',attrs={'data-rpa-tag-id':'historicalDate'}).text\n",
    "                    cur_price = tr.find(name='td',attrs={'data-rpa-tag-id':'historicalPrice'}).text\n",
    "\n",
    "                    # logic to update missing dates and corresponding prices\n",
    "                    if cur_date not in fund_detail['historical_price_table']['date']:\n",
    "                        fund_detail['historical_price_table']['date'].append(cur_date)\n",
    "                        fund_detail['historical_price_table']['price'].append(cur_price)\n",
    "\n",
    "                if index == num_options-1:\n",
    "                    break\n",
    "                listbox_location.click()\n",
    "                time.sleep(random.uniform(0.5,1))\n",
    "                \n",
    "    return fund_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/raw/20231212/urls/funds_url.json','r')as f:\n",
    "    funds_url = json.load(f)\n",
    "\n",
    "\n",
    "try:\n",
    "    for index,(symbol,url) in enumerate(funds_url.items()):\n",
    "        with open(f'../../data/raw/20231212/funds/{symbol}.json','r')as f:\n",
    "            fund_detail = json.load(f)\n",
    "        driver = create_driver()\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(1,1.5))\n",
    "        soup = BeautifulSoup(driver.page_source)\n",
    "        fund_detail = extract_missing_price(soup,fund_detail,driver)\n",
    "        with open(f\"{funds_output_dir}/{symbol}.json\",'w') as f:\n",
    "            json.dump(fund_detail,f)\n",
    "        driver.quit()\n",
    "    \n",
    "    with open(f\"{urls_output_dir}/funds_url.json\",'w')as f:\n",
    "        json.dump(funds_url,f)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ERROR --> {symbol}, Index --> {index}\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "InvestoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
