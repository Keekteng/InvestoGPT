{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium_stealth import stealth\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil import tz\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import undetected_chromedriver as uc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday_date = (datetime.datetime.now(tz=tz.gettz('Asia/Singapore'))-timedelta(days=1)).strftime('%Y%m%d')\n",
    "today_date = (datetime.datetime.now(tz=tz.gettz('Asia/Singapore'))).strftime('%Y%m%d')\n",
    "urls_output_dir = f'../../data/raw/{today_date}/urls'\n",
    "funds_output_dir = f'../../data/raw/{today_date}/funds'\n",
    "\n",
    "os.makedirs(urls_output_dir, exist_ok=True)\n",
    "os.makedirs(funds_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium stealth driver used for scraping \n",
    "def create_driver(debug=False):\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    if debug==False:\n",
    "        options.add_argument(\"--headless\")\n",
    "    # options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    # options.add_experimental_option('useAutomationExtension', False)\n",
    "    driver = uc.Chrome(\n",
    "        options=options\n",
    "    )\n",
    "    stealth(driver,\n",
    "            # user_agent=agent,\n",
    "            languages=[\"en-US\", \"en\"],\n",
    "            vendor=\"Google Inc.\",\n",
    "            platform=\"Win32\",\n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "            renderer=\"Intel Iris OpenGL Engine\",\n",
    "            fix_hairline=True,\n",
    "            )\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_latest_price(html_page_source,fund_detail,driver):\n",
    "\n",
    "    # Only fill in missing price for symbols that have price table\n",
    "    if 'date' in fund_detail['historical_price_table'] and 'price' in fund_detail['historical_price_table']:\n",
    "\n",
    "        if html_page_source.find(name='div',attrs={'id':'mat-tab-label-0-0'}):\n",
    "            tab_1_month = driver.find_element(By.ID,'mat-tab-label-0-0')    \n",
    "            tab_1_month.location_once_scrolled_into_view\n",
    "            time.sleep(random.uniform(1,2))\n",
    "            tab_1_month.click()\n",
    "            time.sleep(random.uniform(2,3))\n",
    "\n",
    "            radio_button = driver.find_element(By.XPATH,\"//input[@type='radio' and @aria-label='table']\")\n",
    "            radio_button.click()\n",
    "            time.sleep(random.uniform(2,4))\n",
    "\n",
    "            listbox_location = driver.find_element(By.XPATH,\"//button[@tabindex='0' and @aria-haspopup='listbox']\")\n",
    "            listbox_location.click()\n",
    "            time.sleep(random.uniform(0,0.5))\n",
    "\n",
    "            overlay_container = driver.find_element(By.XPATH,\"//div[@class='cdk-overlay-container']\")\n",
    "            driver.find_element(By.XPATH,\"//table[@aria-label='Historical prices table']\").location_once_scrolled_into_view\n",
    "            time.sleep(random.uniform(1,2))\n",
    "            listbox = overlay_container.find_element(By.XPATH,\"//div[@role='listbox' and @tabindex='0']\")\n",
    "            num_options = len(listbox.find_elements(By.TAG_NAME,'vui-option'))\n",
    "\n",
    "            # Go to the last page instantly as we only want latest price\n",
    "            option = listbox.find_elements(By.TAG_NAME,'vui-option')[-1]\n",
    "            option.location_once_scrolled_into_view\n",
    "            time.sleep(random.uniform(0.5,1))\n",
    "            option.click()\n",
    "            time.sleep(random.uniform(0.5,1))\n",
    "            updated_page_source = BeautifulSoup(driver.page_source)\n",
    "            price = updated_page_source.find(name='div',attrs={'id':'price_section'})\n",
    "            for tr in price.find(name='table',attrs={'aria-label':'Historical prices table'}).find('tbody').find_all('tr'):\n",
    "                cur_date = tr.find(name='td',attrs={'data-rpa-tag-id':'historicalDate'}).text\n",
    "                cur_price = tr.find(name='td',attrs={'data-rpa-tag-id':'historicalPrice'}).text\n",
    "\n",
    "                # logic to update missing dates and corresponding prices\n",
    "                if cur_date not in fund_detail['historical_price_table']['date']:\n",
    "                    fund_detail['historical_price_table']['date'].append(cur_date)\n",
    "                    fund_detail['historical_price_table']['price'].append(cur_price)\n",
    "                \n",
    "    return fund_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [2:07:54<00:00, 21.93s/it]  \n"
     ]
    }
   ],
   "source": [
    "with open(f'../../data/raw/{yesterday_date}/urls/funds_url.json','r')as f:\n",
    "    funds_url = json.load(f)\n",
    "\n",
    "\n",
    "try:\n",
    "    for index,(symbol,url) in enumerate(tqdm(funds_url.items(),position=0,leave=True)):\n",
    "        if index<70:\n",
    "            continue\n",
    "        with open(f'../../data/raw/{yesterday_date}/funds/{symbol}.json','r')as f:\n",
    "            fund_detail = json.load(f)\n",
    "        driver = create_driver()\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(1,1.5))\n",
    "        soup = BeautifulSoup(driver.page_source)\n",
    "        fund_detail = scrape_latest_price(soup,fund_detail,driver)\n",
    "        with open(f\"{funds_output_dir}/{symbol}.json\",'w') as f:\n",
    "            json.dump(fund_detail,f)\n",
    "        driver.quit()\n",
    "    \n",
    "    with open(f\"{urls_output_dir}/funds_url.json\",'w')as f:\n",
    "        json.dump(funds_url,f)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"ERROR --> {symbol}, Index --> {index}\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "InvestoGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
